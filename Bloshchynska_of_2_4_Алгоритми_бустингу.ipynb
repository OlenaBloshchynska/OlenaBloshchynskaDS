{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "В цьому домашньому завданні ми знову працюємо з даними з нашого змагання [\"Bank Customer Churn Prediction (DLU Course)\"](https://www.kaggle.com/t/7c080c5d8ec64364a93cf4e8f880b6a0).\n",
        "\n",
        "Тут ми побудуємо рішення задачі класифікації з використанням алгоритмів бустингу: XGBoost та LightGBM, а також використаємо бібліотеку HyperOpt для оптимізації гіперпараметрів."
      ],
      "metadata": {
        "id": "fDefDHQt8LXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. Зчитайте дані `train.csv` в змінну `raw_df` та скористайтесь наведеним кодом нижче аби розділити дані на трнувальні та валідаційні і розділити дані на ознаки з матириці Х та цільову змінну. Назви змінних `train_inputs, train_targets, train_inputs, train_targets` можна змінити на ті, які Вам зручно.\n",
        "\n",
        "  Наведений скрипт - частина отриманого мною скрипта для обробки даних. Ми тут не викнуємо масштабування та обробку категоріальних змінних, бо хочемо це делегувати алгоритмам, які будемо використовувати. Якщо щось не розумієте в наведених скриптах, рекомендую розібратись: навичка читати код - важлива складова роботи в машинному навчанні."
      ],
      "metadata": {
        "id": "LhivzW9W8-Dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Add the directory to the Python path\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks')\n",
        "\n",
        "# Зчитування даних з файлу train.csv\n",
        "raw_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/train.csv\")\n",
        "\n",
        "# Припустимо, що остання колонка є цільовою змінною\n",
        "X = raw_df.iloc[:, :-1]  # Всі колонки, крім останньої\n",
        "y = raw_df.iloc[:, -1]   # Остання колонка\n",
        "\n",
        "# Розділення на тренувальні та валідаційні набори\n",
        "train_inputs, val_inputs, train_targets, val_targets = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Виведення розмірів отриманих наборів\n",
        "print(f'Train inputs shape: {train_inputs.shape}')\n",
        "print(f'Train targets shape: {train_targets.shape}')\n",
        "print(f'Validation inputs shape: {val_inputs.shape}')\n",
        "print(f'Validation targets shape: {val_targets.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8xvwCuKlVtR",
        "outputId": "f5fc6793-2a1c-479a-fb8f-068fe545e410"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Train inputs shape: (12000, 13)\n",
            "Train targets shape: (12000,)\n",
            "Validation inputs shape: (3000, 13)\n",
            "Validation targets shape: (3000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Tuple, Dict, Any\n",
        "\n",
        "\n",
        "def split_train_val(df: pd.DataFrame, target_col: str, test_size: float = 0.2, random_state: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Split the dataframe into training and validation sets.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The raw dataframe.\n",
        "        target_col (str): The target column for stratification.\n",
        "        test_size (float): The proportion of the dataset to include in the validation split.\n",
        "        random_state (int): Random state for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, pd.DataFrame]: Training and validation dataframes.\n",
        "    \"\"\"\n",
        "    train_df, val_df = train_test_split(df, test_size=test_size, random_state=random_state, stratify=df[target_col])\n",
        "    return train_df, val_df\n",
        "\n",
        "\n",
        "def separate_inputs_targets(df: pd.DataFrame, input_cols: list, target_col: str) -> Tuple[pd.DataFrame, pd.Series]:\n",
        "    \"\"\"\n",
        "    Separate inputs and targets from the dataframe.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The dataframe.\n",
        "        input_cols (list): List of input columns.\n",
        "        target_col (str): Target column.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, pd.Series]: DataFrame of inputs and Series of targets.\n",
        "    \"\"\"\n",
        "    inputs = df[input_cols].copy()\n",
        "    targets = df[target_col].copy()\n",
        "    return inputs, targets"
      ],
      "metadata": {
        "id": "cKE8RTPf6CRD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. В тренувальному та валідаційному наборі перетворіть категоріальні ознаки на тип `category`. Можна це зробити двома способами:\n",
        " 1. `df[col_name].astype('category')`, як було продемонстровано в лекції\n",
        " 2. використовуючи метод `pd.Categorical(df[col_name])`"
      ],
      "metadata": {
        "id": "cq0JU7MqHgp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Припустимо, що категоріальні ознаки визначені в цьому списку\n",
        "categorical_columns = ['Geography', 'Gender']  # Замініть на ваші категоріальні колонки\n",
        "\n",
        "# Метод 1: Використання astype('category')\n",
        "for col in categorical_columns:\n",
        "    train_inputs[col] = train_inputs[col].astype('category')\n",
        "    val_inputs[col] = val_inputs[col].astype('category')\n",
        "\n",
        "# Метод 2: Використання pd.Categorical\n",
        "for col in categorical_columns:\n",
        "    train_inputs[col] = pd.Categorical(train_inputs[col])\n",
        "    val_inputs[col] = pd.Categorical(val_inputs[col])\n",
        "\n",
        "# Виведення інформації про типи даних для перевірки\n",
        "print(train_inputs.dtypes)\n",
        "print(val_inputs.dtypes)"
      ],
      "metadata": {
        "id": "UPmqo-Mr4yUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c2a132-1586-4cc3-902c-801fe07c5ff2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                    int64\n",
            "CustomerId          float64\n",
            "Surname              object\n",
            "CreditScore         float64\n",
            "Geography          category\n",
            "Gender             category\n",
            "Age                 float64\n",
            "Tenure              float64\n",
            "Balance             float64\n",
            "NumOfProducts       float64\n",
            "HasCrCard           float64\n",
            "IsActiveMember      float64\n",
            "EstimatedSalary     float64\n",
            "dtype: object\n",
            "id                    int64\n",
            "CustomerId          float64\n",
            "Surname              object\n",
            "CreditScore         float64\n",
            "Geography          category\n",
            "Gender             category\n",
            "Age                 float64\n",
            "Tenure              float64\n",
            "Balance             float64\n",
            "NumOfProducts       float64\n",
            "HasCrCard           float64\n",
            "IsActiveMember      float64\n",
            "EstimatedSalary     float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Навчіть на отриманих даних модель `XGBoostClassifier`. Параметри алгоритму встановіть на свій розсуд, ми далі будемо їх тюнити. Рекомендую тренувати не дуже складну модель.\n",
        "\n",
        "  Опис всіх конфігураційних параметрів XGBoostClassifier - тут https://xgboost.readthedocs.io/en/stable/parameter.html#global-config\n",
        "\n",
        "  **Важливо:** зробіть такі налаштування `XGBoostClassifier` аби він самостійно обробляв незаповнені значення в даних і обробляв категоріальні колонки.\n",
        "\n",
        "  Можна також, якщо працюєте в Google Colab, увімкнути можливість використання GPU (`Runtime -> Change runtime type -> T4 GPU`) і встановити параметр `device='cuda'` в `XGBoostClassifier` для пришвидшення тренування бустинг моделі.\n",
        "  \n",
        "  Після тренування моделі\n",
        "  1. Виміряйте точність з допомогою AUROC на тренувальному та валідаційному наборах.\n",
        "  2. Зробіть висновок про отриману модель: вона хороша/погана, чи є high bias/high variance?\n",
        "  3. Порівняйте якість цієї моделі з тою, що ви отрмали з використанням DecisionTrees раніше. Чи вийшло покращити якість?"
      ],
      "metadata": {
        "id": "_LxWkv4o-wMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Перетворення категоріальних ознак на тип category\n",
        "for col in train_inputs.select_dtypes(include=['object', 'category']).columns:\n",
        "    train_inputs[col] = train_inputs[col].astype('category')\n",
        "    val_inputs[col] = val_inputs[col].astype('category')\n",
        "\n",
        "# Ініціалізація та тренування XGBoostClassifier\n",
        "model = XGBClassifier(\n",
        "    use_label_encoder=False,  # Додатковий параметр для уникнення попередження\n",
        "    eval_metric='auc',        # Метрика для валідації\n",
        "    tree_method='gpu_hist',   # Використання GPU\n",
        "    enable_categorical=True   # Обробка категоріальних колонок\n",
        ")\n",
        "\n",
        "# Тренування моделі\n",
        "model.fit(train_inputs, train_targets)\n",
        "\n",
        "# Прогнозування на тренувальних та валідаційних наборах\n",
        "train_preds = model.predict_proba(train_inputs)[:, 1]\n",
        "val_preds = model.predict_proba(val_inputs)[:, 1]\n",
        "\n",
        "# Вимірювання точності з допомогою AUROC\n",
        "train_auc = roc_auc_score(train_targets, train_preds)\n",
        "val_auc = roc_auc_score(val_targets, val_preds)\n",
        "\n",
        "# Виведення результатів\n",
        "print(f'Train AUROC: {train_auc}')\n",
        "print(f'Validation AUROC: {val_auc}')\n",
        "\n",
        "# Висновки\n",
        "if val_auc > 0.7:\n",
        "    print(\"Модель є хорошою.\")\n",
        "else:\n",
        "    print(\"Модель потребує покращення.\")"
      ],
      "metadata": {
        "id": "_5rDqdDP41hb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df18206-fdf0-4b62-9a0e-0cf7d616cfba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train AUROC: 0.9996275383083292\n",
            "Validation AUROC: 0.9138309421138706\n",
            "Модель є хорошою.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:28] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
            "Potential solutions:\n",
            "- Use a data structure that matches the device ordinal in the booster.\n",
            "- Set the device for booster before call to inplace_predict.\n",
            "\n",
            "This warning will only be shown once.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновки\n",
        "\n",
        "Train AUROC 0.9996 - дуже високий показник, майже досягає максимальної можливої точності. Це свідчить про те, що модель дуже добре навчається на тренувальних даних.\n",
        "Validation AUROC 0.9138 - також дуже високий показник, що свідчить про те, що модель добре справляється з новими даними, які вона не бачила під час навчання.\n",
        "\n",
        "Модель є хорошою і значно перевищує поріг 0.7, що вказує на високу точність та гарну узагальненість моделі на нових даних.\n",
        "\n",
        "High Bias - малоймовірно, оскільки модель показує дуже високу точність як на тренувальних, так і на валідаційних даних.\n",
        "\n",
        "High Variance - є невеликий ризик, оскільки є невеликий розрив між Train AUROC і Validation AUROC, але він не критичний. Різниця в AUROC вказує на те, що модель добре узагальнює, хоча може мати деякі елементи перенавчання.\n",
        "\n",
        "В моєму випадку результати значно кращі за DecisionTrees"
      ],
      "metadata": {
        "id": "ZO0JCU2ioJy2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Використовуючи бібліотеку `Hyperopt` і приклад пошуку гіперпараметрів для `XGBoostClassifier` з лекції знайдіть оптимальні значення гіперпараметрів `XGBoostClassifier` для нашої задачі. Задайте свою сітку гіперпараметрів виходячи з тих параметрів, які ви б хотіли перебрати. Поставте кількість раундів в підборі гіперпараметрів рівну **20**.\n",
        "\n",
        "  **Увага!** Для того, аби скористатись hyperopt, нам треба задати функцію `objective`. В ній ми маємо задати loss - це може будь-яка метрика, але бажано використовувтаи ту, яка цільова в вашій задачі. Чим менший лосс - тим ліпша модель на думку hyperopt. Тож, тут нам треба задати loss - негативне значення AUROC. В лекції ми натомість використовували Accuracy.\n",
        "\n",
        "  Після успішного завершення пошуку оптимальних гіперпараметрів\n",
        "    - виведіть найкращі значення гіперпараметрів\n",
        "    - створіть в окремій зміній `final_clf` модель `XGBoostClassifier` з найкращими гіперпараметрами\n",
        "    - навчіть модель `final_clf`\n",
        "    - оцініть якість моделі `final_clf` на тренувальній і валідаційній вибірках з допомогою AUROC.\n",
        "    - зробіть висновок про якість моделі. Чи стала вона краще порівняно з попереднім пунктом (2) цього завдання?"
      ],
      "metadata": {
        "id": "U4hm5qYs_f7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hyperopt xgboost"
      ],
      "metadata": {
        "id": "WhR1g9B4433r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c353c0f9-0934-45d3-9bf9-c6c75b7f4bdb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.66.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost)\n",
            "  Downloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Downloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl (190.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.22.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-nccl-cu12-2.22.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
        "from hyperopt.pyll.base import scope"
      ],
      "metadata": {
        "id": "Ruxrm2t2ovuq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(params):\n",
        "    model = XGBClassifier(\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='auc',\n",
        "        tree_method='gpu_hist',  # Використання GPU\n",
        "        enable_categorical=True,\n",
        "        **params\n",
        "    )\n",
        "    model.fit(train_inputs, train_targets)\n",
        "    val_preds = model.predict_proba(val_inputs)[:, 1]\n",
        "    auc = roc_auc_score(val_targets, val_preds)\n",
        "    return {'loss': -auc, 'status': STATUS_OK}"
      ],
      "metadata": {
        "id": "Xq6JMaPKozLx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "space = {\n",
        "    'n_estimators': scope.int(hp.quniform('n_estimators', 50, 500, 50)),\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
        "    'max_depth': scope.int(hp.quniform('max_depth', 3, 10, 1)),\n",
        "    'min_child_weight': scope.int(hp.quniform('min_child_weight', 1, 10, 1)),\n",
        "    'gamma': hp.uniform('gamma', 0, 0.5),\n",
        "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0, 0.5),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0.5, 1.0)\n",
        "}\n",
        "\n",
        "trials = Trials()\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=20,\n",
        "            trials=trials)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JgQ5N2xo5F9",
        "outputId": "02336a3e-01b0-49b9-a844-3e6c99336d1f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  5%|▌         | 1/20 [00:00<00:16,  1.18trial/s, best loss: -0.9213938427970729]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 10%|█         | 2/20 [00:02<00:25,  1.40s/trial, best loss: -0.9213938427970729]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:51] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:52] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 15%|█▌        | 3/20 [00:04<00:28,  1.66s/trial, best loss: -0.9213938427970729]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:54] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 20%|██        | 4/20 [00:05<00:21,  1.34s/trial, best loss: -0.9220556552781726]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:54] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 25%|██▌       | 5/20 [00:05<00:15,  1.05s/trial, best loss: -0.9227603816384922]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:55] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 30%|███       | 6/20 [00:07<00:17,  1.28s/trial, best loss: -0.9227603816384922]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:56] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:57] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 35%|███▌      | 7/20 [00:09<00:16,  1.29s/trial, best loss: -0.9227603816384922]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:28:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 40%|████      | 8/20 [00:12<00:22,  1.85s/trial, best loss: -0.9227603816384922]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:01] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 45%|████▌     | 9/20 [00:13<00:19,  1.77s/trial, best loss: -0.9227603816384922]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 50%|█████     | 10/20 [00:14<00:15,  1.57s/trial, best loss: -0.9278034329762318]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:15<00:12,  1.37s/trial, best loss: -0.9278034329762318]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 60%|██████    | 12/20 [00:16<00:10,  1.25s/trial, best loss: -0.9278034329762318]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:17<00:07,  1.01s/trial, best loss: -0.9278034329762318]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 70%|███████   | 14/20 [00:18<00:05,  1.03trial/s, best loss: -0.9278034329762318]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 75%|███████▌  | 15/20 [00:19<00:05,  1.14s/trial, best loss: -0.9278034329762318]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:08] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 80%|████████  | 16/20 [00:21<00:04,  1.25s/trial, best loss: -0.9278034329762318]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 85%|████████▌ | 17/20 [00:22<00:03,  1.26s/trial, best loss: -0.9278034329762318]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 90%|█████████ | 18/20 [00:23<00:02,  1.09s/trial, best loss: -0.9278034329762318]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 95%|█████████▌| 19/20 [00:24<00:01,  1.09s/trial, best loss: -0.9278034329762318]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 20/20 [00:24<00:00,  1.22s/trial, best loss: -0.9278034329762318]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best hyperparameters: \", best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9GB29LqpCZh",
        "outputId": "0a6a12cc-20f0-459e-9b27-dd8d14e44ea8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:  {'colsample_bytree': 0.7151961620121172, 'gamma': 0.22026075030455833, 'learning_rate': 0.021680278575909723, 'max_depth': 3.0, 'min_child_weight': 6.0, 'n_estimators': 400.0, 'reg_alpha': 0.48629392389397114, 'reg_lambda': 0.8633236547017025, 'subsample': 0.7269753440879103}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_clf = XGBClassifier(\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='auc',\n",
        "    tree_method='gpu_hist',  # Використання GPU\n",
        "    enable_categorical=True,\n",
        "    n_estimators=int(best['n_estimators']),\n",
        "    learning_rate=best['learning_rate'],\n",
        "    max_depth=int(best['max_depth']),\n",
        "    min_child_weight=int(best['min_child_weight']),\n",
        "    gamma=best['gamma'],\n",
        "    subsample=best['subsample'],\n",
        "    colsample_bytree=best['colsample_bytree'],\n",
        "    reg_alpha=best['reg_alpha'],\n",
        "    reg_lambda=best['reg_lambda']\n",
        ")\n",
        "\n",
        "final_clf.fit(train_inputs, train_targets)\n",
        "\n",
        "# Прогнозування на тренувальних та валідаційних наборах\n",
        "train_preds_final = final_clf.predict_proba(train_inputs)[:, 1]\n",
        "val_preds_final = final_clf.predict_proba(val_inputs)[:, 1]\n",
        "\n",
        "# Вимірювання точності з допомогою AUROC\n",
        "train_auc_final = roc_auc_score(train_targets, train_preds_final)\n",
        "val_auc_final = roc_auc_score(val_targets, val_preds_final)\n",
        "\n",
        "# Виведення результатів\n",
        "print(f'Final Train AUROC: {train_auc_final}')\n",
        "print(f'Final Validation AUROC: {val_auc_final}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1_bAWbcpFJ7",
        "outputId": "84b13255-8235-4257-ef92-3bc955d4a1ff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Train AUROC: 0.9445945888293124\n",
            "Final Validation AUROC: 0.9278034329762318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [22:29:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
            "\n",
            "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train AUROC\n",
        "\n",
        "Зниження - після тюнінгу значення AUROC на тренувальній вибірці знизилось з 0.9996 до 0.9534. Це може свідчити про те, що модель стала менш схильною до перенавчання (overfitting).\n",
        "\n",
        "Висновок. Початково модель мала дуже високу точність на тренувальних даних, що може свідчити про можливе перенавчання. Після тюнінгу цей показник зменшився, що може означати кращу узагальненість моделі.\n",
        "\n",
        "Validation AUROC\n",
        "\n",
        "Покращення - значення AUROC на валідаційній вибірці зросло з 0.9138 до 0.9273. Це свідчить про те, що модель краще узагальнює на невидимих даних.\n",
        "\n",
        "Висновок. Підвищення показника AUROC на валідаційних даних означає, що тюнінг гіперпараметрів допоміг поліпшити якість моделі і її здатність до узагальнення.\n",
        "\n",
        "Загальний висновок\n",
        "Після тюнінгу гіперпараметрів ми отримали кращий результат на валідаційних даних, що є основним показником якості моделі.Підтвердження покращення валідаційного AUROC при деякому зниженні тренувального AUROC вказує на зменшення перенавчання.\n",
        "Таким чином, можна зробити висновок, що тюнінг гіперпараметрів допоміг покращити якість моделі, зробивши її менш схильною до перенавчання та кращою у здатності узагальнювати на нових даних."
      ],
      "metadata": {
        "id": "T7lfo0fFpeMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Навчіть на наших даних модель LightGBM. Параметри алгоритму встановіть на свій розсуд, ми далі будемо їх тюнити. Рекомендую тренувати не дуже складну модель.\n",
        "\n",
        "  Опис всіх конфігураційних параметрів LightGBM - тут https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
        "\n",
        "  **Важливо:** зробіть такі налаштування LightGBM аби він самостійно обробляв незаповнені значення в даних і обробляв категоріальні колонки.\n",
        "\n",
        "  Аби передати категоріальні колонки в LightGBM - необхідно виявити їх індекси і передати в параметрі `cat_feature=cat_feature_indexes`\n",
        "\n",
        "  Після тренування моделі\n",
        "  1. Виміряйте точність з допомогою AUROC на тренувальному та валідаційному наборах.\n",
        "  2. Зробіть висновок про отриману модель: вона хороша/погана, чи є high bias/high variance?\n",
        "  3. Порівняйте якість цієї моделі з тою, що ви отрмали з використанням XGBoostClassifier раніше. Чи вийшло покращити якість?"
      ],
      "metadata": {
        "id": "Vg77SVWrBBmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm\n",
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "C-9aZn4d45No",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d913c20f-32c7-4908-aae9-dd040104dc67"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.13.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Індекси категоріальних колонок для LightGBM\n",
        "cat_feature_indexes = [train_inputs.columns.get_loc(col) for col in train_inputs.select_dtypes(include=['category']).columns]"
      ],
      "metadata": {
        "id": "vnUAHrmmp9FU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Налаштування параметрів LightGBM\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'auc',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'learning_rate': 0.1,\n",
        "    'num_leaves': 31,\n",
        "    'max_depth': -1,  # No limit\n",
        "    'categorical_feature': cat_feature_indexes,\n",
        "    'verbose': -1\n",
        "}\n",
        "\n",
        "# Створення LightGBM Dataset\n",
        "train_data = lgb.Dataset(train_inputs, label=train_targets, categorical_feature=cat_feature_indexes)\n",
        "val_data = lgb.Dataset(val_inputs, label=val_targets, categorical_feature=cat_feature_indexes, reference=train_data)\n",
        "\n",
        "# Навчання моделі з ранньою зупинкою за допомогою callbacks\n",
        "model = lgb.train(\n",
        "    params,\n",
        "    train_data,\n",
        "    valid_sets=[val_data],\n",
        "    valid_names=['valid'],\n",
        "    num_boost_round=1000,\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=50)]  # Використання ранньої зупинки\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK4bADp6qETZ",
        "outputId": "0abcac7c-ccc6-4fc9-98fd-1e702c4c1f98"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:2108: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py:2108: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[23]\tvalid's auc: 0.920091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Прогнозування на тренувальних та валідаційних наборах\n",
        "train_preds = model.predict(train_inputs)\n",
        "val_preds = model.predict(val_inputs)\n",
        "\n",
        "# Вимірювання точності з допомогою AUROC\n",
        "train_auc = roc_auc_score(train_targets, train_preds)\n",
        "val_auc = roc_auc_score(val_targets, val_preds)\n",
        "\n",
        "# Виведення результатів\n",
        "print(f'Train AUROC: {train_auc}')\n",
        "print(f'Validation AUROC: {val_auc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClRl2XZnrGCK",
        "outputId": "ba7fb5f4-8255-479e-f6e9-d767c6eb26eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train AUROC: 0.9586274698319173\n",
            "Validation AUROC: 0.9200910042451214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train AUROC - модель XGBoost демонструє вищий AUROC на тренувальних даних, що вказує на можливе переобладнання (overfitting). Високий тренувальний AUROC і дуже низький валідаційний AUROC у XGBoost вказують на те, що модель XGBoost може мати високий variance.\n",
        "\n",
        "Validation AUROC - LightGBM показує трохи кращий результат на валідаційних даних порівняно з XGBoost. Це свідчить про те, що LightGBM краще узагальнює на нових даних і менш схильний до переобладнання порівняно з XGBoost.\n",
        "\n",
        "Висновок\n",
        "Модель LightGBM має високий AUROC на тренувальних та валідаційних даних, що свідчить про хорошу продуктивність і помірний рівень переобладнання.\n",
        "В порівнянні з XGBoostClassifier, LightGBM має кращі результати на валідаційних даних. Це свідчить про те, що LightGBM краще узагальнює на нових даних і може бути кращим вибором для цієї задачі.\n",
        "Загалом, LightGBM забезпечує кращу якість моделі на валідаційних даних порівняно з XGBoost, що робить його кращим вибором для цієї конкретної задачі."
      ],
      "metadata": {
        "id": "DpYGjBNLrX9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Використовуючи бібліотеку `Hyperopt` і приклад пошуку гіперпараметрів для `LightGBM` з лекції знайдіть оптимальні значення гіперпараметрів `LightGBM` для нашої задачі. Задайте свою сітку гіперпараметрів виходячи з тих параметрів, які ви б хотіли перебрати. Поставте кількість раундів в підборі гіперпараметрів рівну **10**.\n",
        "\n",
        "  **Увага!** Для того, аби скористатись hyperopt, нам треба задати функцію `objective`. І тут ми також ставимо loss - негативне значення AUROC, як і при пошуці гіперпараметрів для XGBoost. До речі, можна спробувати написати код так, аби в objective передавати лише модель і не писати схожий код двічі :)\n",
        "\n",
        "  Після успішного завершення пошуку оптимальних гіперпараметрів\n",
        "    - виведіть найкращі значення гіперпараметрів\n",
        "    - створіть в окремій зміній `final_lgb_clf` модель `LightGBM` з найкращими гіперпараметрами\n",
        "    - навчіть модель `final_lgb_clf`\n",
        "    - оцініть якість моделі `final_lgb_clf` на тренувальній і валідаційній вибірках з допомогою AUROC.\n",
        "    - зробіть висновок про якість моделі. Чи стала вона краще порівняно з попереднім пунктом (4) цього завдання?"
      ],
      "metadata": {
        "id": "nCnkGD_sEW1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm hyperopt"
      ],
      "metadata": {
        "id": "cfMQKA4D47Rq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda3d1bc-3c5e-42fe-ec2f-2756591fcf6d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.4.0)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.66.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
        "# Індекси категоріальних колонок для LightGBM\n",
        "cat_feature_indexes = [train_inputs.columns.get_loc(col) for col in train_inputs.select_dtypes(include=['category']).columns]\n",
        "\n",
        "# Створення LightGBM Dataset з параметром free_raw_data=False\n",
        "train_data = lgb.Dataset(train_inputs, label=train_targets, categorical_feature=cat_feature_indexes, free_raw_data=False)\n",
        "val_data = lgb.Dataset(val_inputs, label=val_targets, categorical_feature=cat_feature_indexes, reference=train_data, free_raw_data=False)"
      ],
      "metadata": {
        "id": "TnEK1f8XrqBG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(params):\n",
        "    # Налаштування параметрів LightGBM\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'auc',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'verbose': -1,\n",
        "        **params\n",
        "    }\n",
        "\n",
        "    # Навчання моделі\n",
        "    model = lgb.train(\n",
        "        params,\n",
        "        train_data,\n",
        "        valid_sets=[val_data],\n",
        "        valid_names=['valid'],\n",
        "        num_boost_round=1000,\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
        "    )\n",
        "\n",
        "    # Прогнозування на валідаційних даних\n",
        "    val_preds = model.predict(val_inputs)\n",
        "\n",
        "    # Вимірювання AUROC\n",
        "    val_auc = roc_auc_score(val_targets, val_preds)\n",
        "\n",
        "    # Оптимізація: мінімізуємо негативний AUROC\n",
        "    return {\n",
        "        'loss': -val_auc,\n",
        "        'status': STATUS_OK\n",
        "    }"
      ],
      "metadata": {
        "id": "r9jZbY44rygm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "space = {\n",
        "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
        "    'num_leaves': hp.choice('num_leaves', [31, 63, 127]),  # Зазначити значення більше 1\n",
        "    'max_depth': hp.choice('max_depth', [-1, 10, 20, 30]),\n",
        "    'min_child_samples': hp.choice('min_child_samples', [10, 20, 30]),\n",
        "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
        "    'reg_alpha': hp.uniform('reg_alpha', 0, 1),\n",
        "    'reg_lambda': hp.uniform('reg_lambda', 0, 1)\n",
        "}"
      ],
      "metadata": {
        "id": "7Ap6u-8qr2N3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
        "\n",
        "# Запуск оптимізації Hyperopt\n",
        "trials = Trials()\n",
        "best = fmin(\n",
        "    fn=objective,\n",
        "    space=space,\n",
        "    algo=tpe.suggest,\n",
        "    max_evals=10,  # Кількість раундів\n",
        "    trials=trials\n",
        ")\n",
        "\n",
        "print(f'Best hyperparameters: {best}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0onQZXiRr4rd",
        "outputId": "0ae0e9f5-9ba3-4b1b-aa8b-3f2d5f4a731a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid's auc: 0.927728\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[23]\tvalid's auc: 0.92994\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[36]\tvalid's auc: 0.918994\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[13]\tvalid's auc: 0.920568\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[65]\tvalid's auc: 0.920408\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[8]\tvalid's auc: 0.924208\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid's auc: 0.924882\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[14]\tvalid's auc: 0.927086\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[13]\tvalid's auc: 0.928024\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[5]\tvalid's auc: 0.924593\n",
            "100%|██████████| 10/10 [00:22<00:00,  2.26s/trial, best loss: -0.9299404100555264]\n",
            "Best hyperparameters: {'colsample_bytree': 0.681771896496937, 'learning_rate': 0.05945955514350719, 'max_depth': 0, 'min_child_samples': 1, 'num_leaves': 2, 'reg_alpha': 0.7287896497960138, 'reg_lambda': 0.9963811624413942, 'subsample': 0.6379713934787902}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Налаштування найкращих параметрів\n",
        "best_params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'auc',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'verbose': -1,\n",
        "    **best\n",
        "}\n",
        "\n",
        "# Створення фінальної моделі\n",
        "final_lgb_clf = lgb.train(\n",
        "    best_params,\n",
        "    train_data,\n",
        "    valid_sets=[val_data],\n",
        "    valid_names=['valid'],\n",
        "    num_boost_round=1000,\n",
        "    callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
        ")\n",
        "\n",
        "# Прогнозування на тренувальних та валідаційних наборах\n",
        "train_preds = final_lgb_clf.predict(train_inputs)\n",
        "val_preds = final_lgb_clf.predict(val_inputs)\n",
        "\n",
        "# Вимірювання AUROC\n",
        "train_auc = roc_auc_score(train_targets, train_preds)\n",
        "val_auc = roc_auc_score(val_targets, val_preds)\n",
        "\n",
        "print(f'Final Train AUROC: {train_auc}')\n",
        "print(f'Final Validation AUROC: {val_auc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07Z-jsu0sXAq",
        "outputId": "12421480-d751-448b-f417-b9d7bafe3663"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training until validation scores don't improve for 50 rounds\n",
            "Early stopping, best iteration is:\n",
            "[565]\tvalid's auc: 0.917189\n",
            "Final Train AUROC: 0.9444019369731729\n",
            "Final Validation AUROC: 0.9171886178981721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train AUROC 0.9446 – це висока точність на тренувальних даних, що вказує на добре підходження моделі до навчальних даних.\n",
        "\n",
        "Validation AUROC 0.9171 – це також висока точність на валідаційних даних, що свідчить про хорошу узагальненість моделі.\n",
        "Порівняння з попередніми моделями:\n",
        "\n",
        "Хоча LightGBM показала дуже хороші результати, XGBoost мала трохи кращу точність на валідаційних даних. Це може вказувати на те, що модель XGBoost краще підійшла для даних у цьому конкретному випадку.\n",
        "\n",
        "Модель LightGBM показала дуже хороші результати, але XGBoost залишилася трохи кращою за точністю на валідаційних даних. Однак, обидві моделі демонструють відмінну якість, і обрана модель може залежати від подальших вимог або специфічних характеристик даних.\n",
        "\n",
        "Якщо точність на валідаційних даних є критично важливою, можна продовжити використовувати XGBoost. Однак, якщо LightGBM демонструє кращу ефективність у термінах швидкості навчання або ресурсів, то вона також є хорошим вибором."
      ],
      "metadata": {
        "id": "8QFN0tPbuGx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Оберіть модель з експериментів в цьому ДЗ і зробіть новий `submission` на Kaggle та додайте код для цього і скріншот скора на публічному лідерборді.\n",
        "  \n",
        "  **Напишіть коментар, чому ви обрали саме цю модель?**\n",
        "\n",
        "  І я вас вітаю - це останнє завдання з цим набором даних 💪 На цьому етапі корисно проаналізувати, які моделі показали себе найкраще і подумати, чому."
      ],
      "metadata": {
        "id": "XArADR2CG8VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lYKCnvvpuGLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Завантаження даних\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/test.csv')\n",
        "submission = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sample_submission.csv')\n",
        "\n",
        "# Визначення категоріальних ознак\n",
        "categorical_features = ['Geography', 'Gender']\n",
        "\n",
        "# Функція для обробки категоріальних колонок\n",
        "def preprocess_data(df: pd.DataFrame, categorical_features: list) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    for col in categorical_features:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.Categorical(df[col])\n",
        "    return df\n",
        "\n",
        "# Обробка тренувальних даних\n",
        "train_df = preprocess_data(train_df, categorical_features)\n",
        "\n",
        "# Збереження категорій з тренувальних даних\n",
        "saved_categories = {col: train_df[col].cat.categories for col in categorical_features}\n",
        "\n",
        "# Функція для обробки нових даних з урахуванням категорій\n",
        "def preprocess_new_data(df: pd.DataFrame, categorical_features: list, saved_categories: dict) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    for col in categorical_features:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.Categorical(df[col], categories=saved_categories.get(col, []))\n",
        "            df[col] = df[col].cat.codes\n",
        "    return df\n",
        "\n",
        "# Видалення стовпця 'Surname' з тренувальних і тестових даних\n",
        "train_df = train_df.drop(columns=['Surname'])\n",
        "test_df = test_df.drop(columns=['Surname'])\n",
        "\n",
        "# Обробка тренувальних даних для моделі\n",
        "processed_train = preprocess_new_data(train_df, categorical_features, saved_categories)\n",
        "\n",
        "# Обробка тестових даних\n",
        "preprocessed_test = preprocess_new_data(test_df, categorical_features, saved_categories)\n",
        "\n",
        "# Визначення характеристик і мети\n",
        "X_train = processed_train.drop(['id', 'Exited'], axis=1)\n",
        "y_train = processed_train['Exited']\n",
        "\n",
        "# Створення і тренування моделі\n",
        "final_lgb_clf = lgb.LGBMClassifier()\n",
        "final_lgb_clf.fit(X_train, y_train, categorical_feature=categorical_features)\n",
        "\n",
        "# Передбачення на тестових даних\n",
        "proba_predictions = final_lgb_clf.predict(preprocessed_test.drop('id', axis=1))\n",
        "\n",
        "# Додавання прогнозів у DataFrame для submission\n",
        "submission = submission[['id']].copy()  # Оновлення колонок для submission\n",
        "submission['Exited'] = proba_predictions\n",
        "\n",
        "# Перегляд результатів\n",
        "print(submission.head())\n",
        "\n",
        "# Збереження submission-файлу\n",
        "submission.to_csv('/content/drive/MyDrive/Colab Notebooks/submission.csv', index=False)"
      ],
      "metadata": {
        "id": "COIjJH9f5SSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ed810b-78c0-44a9-a751-e4f6e33b9f97"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 3052, number of negative: 11948\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001506 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1100\n",
            "[LightGBM] [Info] Number of data points in the train set: 15000, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203467 -> initscore=-1.364767\n",
            "[LightGBM] [Info] Start training from score -1.364767\n",
            "      id  Exited\n",
            "0  15000     0.0\n",
            "1  15001     0.0\n",
            "2  15002     0.0\n",
            "3  15003     1.0\n",
            "4  15004     0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На жаль, не встигла вчасно засабмітити:("
      ],
      "metadata": {
        "id": "WYt9_W6poWsD"
      }
    }
  ]
}